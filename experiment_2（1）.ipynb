{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实验目标：**\n",
    "\n",
    "通过本实验，你将深入了解和实践说话人识别技术，并掌握利用声音特征进行有效说话人识别的基本方法，了解不同特征和模型对识别准确率的影响。\n",
    "\n",
    "实验的核心目标是使用TIMIT数据集来训练一个说话人识别系统，涵盖数据预处理、特征提取、模型训练和评估等关键步骤。\n",
    "\n",
    "\n",
    "**实验方法：**\n",
    "\n",
    "**1. 数据预处理和划分(可选)：**\n",
    "  - 数据集下载地址（4月17日前有效）：https://f.ws59.cn/f/du8yd2536vl\n",
    "  - 为了方便大家，我们提供了划分好的TIMIT数据集结构，当然你也可以根据需求自行划分该数据集。\n",
    "  - 为简化难度，我们排除了SA的两个方言句子，并在剩余的8个句子中选取了SX的5个句子和SI的1个句子作为训练集，SI的另外2个句子作为测试集。\n",
    "  - 该链接下载的数据集只保留了音频文件，完整数据集（包含音频对应文本、标注等信息）可参见备注链接下载。\n",
    "  \n",
    "**2. 特征提取：**\n",
    "  - 学习并实现包括但不限于MFCC特征等特征的提取，探索声音信号的频率和时间特性。\n",
    "  - 鼓励尝试和比较其他特征提取方法，例如LPCC或声谱图特征，以理解不同特征对识别性能的影响。\n",
    "  \n",
    "**3. 模型选择和训练：**\n",
    "  - 探索并选择适合的分类器和模型进行说话人识别，如GMM、Softmax分类器或深度学习模型。\n",
    "  - 实现模型训练流程，使用训练集数据训练模型。\n",
    "  \n",
    "**4. 评估和分析：**\n",
    "  - 使用准确率作为主要的评价指标在测试集上评估模型性能。\n",
    "  - 对比不同特征和模型的性能，分析其对说话人识别准确率的影响。\n",
    "  - 可视化不同模型的识别结果和错误率，讨论可能的改进方法。\n",
    "\n",
    "**实验要求：**\n",
    "  - 1.选择并实现至少一种特征的提取，并鼓励尝试其他特征提取方法。\n",
    "  - 2.选择并实现至少一种分类器或模型进行说话人识别，并使用准确率评估指标评估其性能。\n",
    "  - 3.通过实验对比、分析和可视化，撰写详细的实验报告，包括实验目的、实验方法、结果分析和结论。\n",
    "  - 4.实验报告应以清晰、逻辑性强的形式呈现，图表和结果应清楚明了。\n",
    "\n",
    "**其他说明：**\n",
    "  - 实验的最终打分环节会看识别性能，会对原理和实现代码部分做抽查提问，综合评定成绩。\n",
    "  - 我们**鼓励做原创性探索**，即使性能不是很好，但有创新性、有价值、有意义的探索和尝试会有额外加分。\n",
    "  - 原数完整据集下载地址：https://drive.google.com/file/d/180mSIiXN9RVDV2Xn1xcWNkMRm5J5MjN4/view?usp=sharing \\\n",
    "    或国内访问地址（4月17日前有效）：https://f.ws59.cn/f/du8xu130kba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入必要的库\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 可以根据需要导入其他库，比如librosa用于音频处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据预处理(加载数据集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR6F\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-57.8917, -53.9269, -55.0987,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [-69.2721, -67.7900, -64.8125,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [-68.4775, -68.9569, -68.0512,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         ...,\n",
       "         [-69.5185, -70.8639, -72.3317,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [-69.0080, -69.5373, -72.6931,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [-71.5765, -70.6174, -72.2338,  ...,   0.0000,   0.0000,   0.0000]]),\n",
       " tensor(11))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 请从如下地址下载数据集（4月17日前有效）：https://f.ws59.cn/f/du8yd2536vl\n",
    "# 数据集基本信息如下\n",
    "# 方言地区：DR1～DR8\n",
    "# 性别：F/M\n",
    "# 说话者ID：3大写字母+1阿拉伯数字\n",
    "# 句子ID：句子类型（SA/SI/SX）+编号\n",
    "# 详细介绍参见 https://blog.csdn.net/qq_39373179/article/details/103788208\n",
    "\n",
    "# 上述链接下载的数据集已经\n",
    "TrainDir = \"Dataset/TRAIN\"\n",
    "TestDir = \"Dataset/TEST\"\n",
    "## 请在这里写代码加载我们划分好的TIMIT训练集和测试集。或者原始完整版数据集。\n",
    "\n",
    "\n",
    "def pad_or_truncate(array, max_length):\n",
    "    \"\"\";\"\"\"\n",
    "    if array.shape[1] < max_length:\n",
    "        pad_size = max_length - array.shape[1]\n",
    "        array = np.pad(\n",
    "            array, ((0, 0), (0, pad_size)), mode=\"constant\", constant_values=(0, 0)\n",
    "        )\n",
    "    else:\n",
    "        array = array[:, :max_length]\n",
    "    return array\n",
    "\n",
    "\n",
    "class trainset(Dataset):\n",
    "    def __init__(self, dir, mode=0):\n",
    "        self.mode = mode\n",
    "        self.dir_path = dir\n",
    "        self.drs = os.listdir(self.dir_path)\n",
    "        self.wavs = dict()  # wav 文件名：标注\n",
    "        self.label_to_index = {}  # 字典存储标签和索引\n",
    "        self.current_index = 0\n",
    "\n",
    "        # 初始化字典并填充 wav 列表\n",
    "        for dr in self.drs:\n",
    "            speakers = os.listdir(os.path.join(self.dir_path, dr))\n",
    "            for s in speakers:\n",
    "                wavs = os.listdir(os.path.join(self.dir_path, dr, s))\n",
    "                for w in wavs:\n",
    "                    if w.split(\".\")[-1] == \"WAV\":\n",
    "                        label = dr + s[:1]  # 创建标签\n",
    "                        if label not in self.label_to_index:\n",
    "                            self.label_to_index[label] = self.current_index\n",
    "                            self.current_index += 1\n",
    "                        self.wavs[os.path.join(self.dir_path, dr, s, w)] = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        wav = list(self.wavs.keys())[index]\n",
    "        label = self.wavs[wav]\n",
    "        # 获取标签对应的索引\n",
    "        label_index = self.label_to_index[label]\n",
    "        # 将标签索引转换为张量\n",
    "        label_tensor = torch.tensor(label_index, dtype=torch.long).to(device)\n",
    "        waveform, sample_rate = torchaudio.load(wav)\n",
    "\n",
    "        if self.mode == 0:\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=waveform.numpy()[0], sr=sample_rate, n_mfcc=13\n",
    "            )\n",
    "            mfcc_db = librosa.power_to_db(mfcc, ref=np.max)\n",
    "            max_length = 128  # 这个值可以根据数据集中最长的样本来设置\n",
    "            mfcc_db = pad_or_truncate(mfcc_db, max_length)\n",
    "\n",
    "            mfcc_db = torch.tensor(mfcc).float().to(device)\n",
    "            return mfcc_db, label_tensor\n",
    "        else:\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=waveform.numpy()[0], sr=sample_rate\n",
    "            )\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            max_length = 128  # 这个值可以根据数据集中最长的样本来设置\n",
    "            mel_spec_db = pad_or_truncate(mel_spec_db, max_length)\n",
    "\n",
    "            mel_spec_db = torch.tensor(mel_spec_db).float().to(device)\n",
    "\n",
    "            return mel_spec_db, label_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wavs)\n",
    "\n",
    "    def target(self):\n",
    "        return len(self.label_to_index)\n",
    "\n",
    "\n",
    "train_dataset = trainset(TrainDir, 1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_dataset = trainset(TestDir, 1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
    "target = train_dataset.target()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请编写或使用库函数提取MFCC等音频特征\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型选择和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR5M\n",
      "DR7M\n",
      "DR2M\n",
      "DR5M\n",
      "DR3F\n",
      "DR7M\n",
      "DR3M\n",
      "DR4F\n",
      "DR2M\n",
      "DR2M\n",
      "DR1M\n",
      "DR5M\n",
      "DR5F\n",
      "DR1F\n",
      "DR7M\n",
      "DR8M\n",
      "DR7F\n",
      "DR5M\n",
      "DR3M\n",
      "DR5F\n",
      "DR4F\n",
      "DR7M\n",
      "DR3F\n",
      "DR5M\n",
      "DR3M\n",
      "DR1M\n",
      "DR6F\n",
      "DR2M\n",
      "DR4M\n",
      "DR2F\n",
      "DR7M\n",
      "DR5M\n",
      "DR6M\n",
      "DR3M\n",
      "DR2M\n",
      "DR4M\n",
      "DR7M\n",
      "DR3M\n",
      "DR3M\n",
      "DR3F\n",
      "DR5F\n",
      "DR7M\n",
      "DR8M\n",
      "DR2M\n",
      "DR3M\n",
      "DR4M\n",
      "DR3M\n",
      "DR1F\n",
      "DR3F\n",
      "DR2M\n",
      "DR3F\n",
      "DR8F\n",
      "DR7M\n",
      "DR6M\n",
      "DR3F\n",
      "DR6M\n",
      "DR3F\n",
      "DR6F\n",
      "DR2F\n",
      "DR5M\n",
      "DR2M\n",
      "DR3M\n",
      "DR5M\n",
      "DR2F\n",
      "DR3F\n",
      "DR5M\n",
      "DR7M\n",
      "DR7M\n",
      "DR4M\n",
      "DR4M\n",
      "DR3M\n",
      "DR2M\n",
      "DR5F\n",
      "DR3M\n",
      "DR5F\n",
      "DR4M\n",
      "DR3M\n",
      "DR6M\n",
      "DR7M\n",
      "DR7M\n",
      "DR5F\n",
      "DR4M\n",
      "DR3M\n",
      "DR8M\n",
      "DR6M\n",
      "DR1F\n",
      "DR2M\n",
      "DR1M\n",
      "DR7M\n",
      "DR3M\n",
      "DR2M\n",
      "DR4M\n",
      "DR3M\n",
      "DR6M\n",
      "DR5M\n",
      "DR7M\n",
      "DR2F\n",
      "DR5F\n",
      "DR3M\n",
      "DR4M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]:   2%|▏         | 1/47 [00:02<01:39,  2.16s/it, loss=3.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR7M\n",
      "DR2M\n",
      "DR5M\n",
      "DR3M\n",
      "DR7F\n",
      "DR7M\n",
      "DR3M\n",
      "DR4M\n",
      "DR2M\n",
      "DR2F\n",
      "DR1F\n",
      "DR5M\n",
      "DR5M\n",
      "DR8F\n",
      "DR4M\n",
      "DR4F\n",
      "DR2M\n",
      "DR5F\n",
      "DR3M\n",
      "DR6F\n",
      "DR7F\n",
      "DR4M\n",
      "DR5F\n",
      "DR1F\n",
      "DR3M\n",
      "DR7M\n",
      "DR3M\n",
      "DR2M\n",
      "DR8M\n",
      "DR7M\n",
      "DR4M\n",
      "DR2F\n",
      "DR5M\n",
      "DR3M\n",
      "DR5F\n",
      "DR1M\n",
      "DR5M\n",
      "DR6F\n",
      "DR6F\n",
      "DR8M\n",
      "DR7M\n",
      "DR2M\n",
      "DR2M\n",
      "DR8M\n",
      "DR6M\n",
      "DR4M\n",
      "DR1F\n",
      "DR1F\n",
      "DR2M\n",
      "DR6M\n",
      "DR2F\n",
      "DR3M\n",
      "DR3F\n",
      "DR2F\n",
      "DR4M\n",
      "DR7M\n",
      "DR2F\n",
      "DR2F\n",
      "DR4M\n",
      "DR1M\n",
      "DR7M\n",
      "DR3M\n",
      "DR3M\n",
      "DR4F\n",
      "DR7M\n",
      "DR7M\n",
      "DR4F\n",
      "DR4M\n",
      "DR2F\n",
      "DR2F\n",
      "DR6F\n",
      "DR2F\n",
      "DR7M\n",
      "DR7F\n",
      "DR4M\n",
      "DR3M\n",
      "DR4M\n",
      "DR4M\n",
      "DR3M\n",
      "DR3F\n",
      "DR5M\n",
      "DR5M\n",
      "DR2M\n",
      "DR2F\n",
      "DR2F\n",
      "DR7M\n",
      "DR5M\n",
      "DR1M\n",
      "DR8M\n",
      "DR7M\n",
      "DR1F\n",
      "DR2M\n",
      "DR5F\n",
      "DR1M\n",
      "DR1M\n",
      "DR5M\n",
      "DR4F\n",
      "DR5M\n",
      "DR4M\n",
      "DR3M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]:   4%|▍         | 2/47 [00:03<01:14,  1.65s/it, loss=82.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR7M\n",
      "DR6M\n",
      "DR3F\n",
      "DR5M\n",
      "DR7M\n",
      "DR3M\n",
      "DR7M\n",
      "DR1M\n",
      "DR3F\n",
      "DR4M\n",
      "DR5M\n",
      "DR5F\n",
      "DR5F\n",
      "DR4M\n",
      "DR7F\n",
      "DR5M\n",
      "DR7M\n",
      "DR2M\n",
      "DR7M\n",
      "DR7M\n",
      "DR1M\n",
      "DR2M\n",
      "DR2F\n",
      "DR8F\n",
      "DR2M\n",
      "DR7M\n",
      "DR3M\n",
      "DR4M\n",
      "DR7F\n",
      "DR5M\n",
      "DR4M\n",
      "DR1F\n",
      "DR2F\n",
      "DR5M\n",
      "DR3M\n",
      "DR2M\n",
      "DR5F\n",
      "DR4M\n",
      "DR6F\n",
      "DR7M\n",
      "DR5F\n",
      "DR2M\n",
      "DR4F\n",
      "DR3M\n",
      "DR2M\n",
      "DR5F\n",
      "DR6F\n",
      "DR5M\n",
      "DR4M\n",
      "DR7M\n",
      "DR5M\n",
      "DR4M\n",
      "DR5F\n",
      "DR3M\n",
      "DR5M\n",
      "DR7M\n",
      "DR5F\n",
      "DR2M\n",
      "DR1M\n",
      "DR4F\n",
      "DR8M\n",
      "DR2M\n",
      "DR3M\n",
      "DR4M\n",
      "DR5M\n",
      "DR2M\n",
      "DR5F\n",
      "DR4M\n",
      "DR7M\n",
      "DR3M\n",
      "DR6M\n",
      "DR8M\n",
      "DR5F\n",
      "DR6M\n",
      "DR8M\n",
      "DR4M\n",
      "DR3M\n",
      "DR7F\n",
      "DR8M\n",
      "DR5M\n",
      "DR2M\n",
      "DR6M\n",
      "DR3M\n",
      "DR4M\n",
      "DR3F\n",
      "DR4M\n",
      "DR3F\n",
      "DR8F\n",
      "DR3M\n",
      "DR5F\n",
      "DR5M\n",
      "DR5M\n",
      "DR3F\n",
      "DR3M\n",
      "DR8M\n",
      "DR7M\n",
      "DR6F\n",
      "DR2M\n",
      "DR2M\n",
      "DR7M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]:   6%|▋         | 3/47 [00:04<01:08,  1.56s/it, loss=86.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR6M\n",
      "DR7M\n",
      "DR3M\n",
      "DR2M\n",
      "DR7M\n",
      "DR6F\n",
      "DR6F\n",
      "DR1M\n",
      "DR2M\n",
      "DR3M\n",
      "DR2F\n",
      "DR3F\n",
      "DR4M\n",
      "DR3M\n",
      "DR7M\n",
      "DR7M\n",
      "DR2M\n",
      "DR2F\n",
      "DR5F\n",
      "DR6M\n",
      "DR2M\n",
      "DR7M\n",
      "DR5F\n",
      "DR3M\n",
      "DR4M\n",
      "DR1M\n",
      "DR8M\n",
      "DR4F\n",
      "DR7M\n",
      "DR4M\n",
      "DR6M\n",
      "DR6F\n",
      "DR7F\n",
      "DR6M\n",
      "DR2M\n",
      "DR6M\n",
      "DR3M\n",
      "DR1F\n",
      "DR5F\n",
      "DR8M\n",
      "DR6M\n",
      "DR8M\n",
      "DR7M\n",
      "DR2M\n",
      "DR2F\n",
      "DR7F\n",
      "DR1F\n",
      "DR4M\n",
      "DR6M\n",
      "DR5F\n",
      "DR3M\n",
      "DR4F\n",
      "DR3M\n",
      "DR7M\n",
      "DR5M\n",
      "DR2M\n",
      "DR6M\n",
      "DR6F\n",
      "DR3M\n",
      "DR4M\n",
      "DR3M\n",
      "DR3F\n",
      "DR5M\n",
      "DR2M\n",
      "DR4M\n",
      "DR4M\n",
      "DR3F\n",
      "DR7M\n",
      "DR1F\n",
      "DR7M\n",
      "DR8M\n",
      "DR5M\n",
      "DR5M\n",
      "DR5M\n",
      "DR5F\n",
      "DR1F\n",
      "DR5M\n",
      "DR1F\n",
      "DR4F\n",
      "DR7M\n",
      "DR4M\n",
      "DR4M\n",
      "DR4M\n",
      "DR7M\n",
      "DR3M\n",
      "DR7M\n",
      "DR4F\n",
      "DR7M\n",
      "DR3M\n",
      "DR8M\n",
      "DR3M\n",
      "DR1M\n",
      "DR4M\n",
      "DR2M\n",
      "DR5M\n",
      "DR4M\n",
      "DR8M\n",
      "DR6M\n",
      "DR7M\n",
      "DR5M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]:   9%|▊         | 4/47 [00:06<01:03,  1.48s/it, loss=62.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR5M\n",
      "DR7F\n",
      "DR3M\n",
      "DR4M\n",
      "DR4M\n",
      "DR3F\n",
      "DR2F\n",
      "DR2F\n",
      "DR8M\n",
      "DR7M\n",
      "DR2M\n",
      "DR5M\n",
      "DR3M\n",
      "DR7M\n",
      "DR5M\n",
      "DR6F\n",
      "DR7M\n",
      "DR1F\n",
      "DR6M\n",
      "DR6F\n",
      "DR2M\n",
      "DR5M\n",
      "DR7M\n",
      "DR5F\n",
      "DR7M\n",
      "DR5F\n",
      "DR4M\n",
      "DR4M\n",
      "DR8M\n",
      "DR7M\n",
      "DR7M\n",
      "DR7M\n",
      "DR7M\n",
      "DR7F\n",
      "DR7M\n",
      "DR7M\n",
      "DR3F\n",
      "DR3M\n",
      "DR4M\n",
      "DR4M\n",
      "DR2F\n",
      "DR8F\n",
      "DR7F\n",
      "DR2M\n",
      "DR7F\n",
      "DR4M\n",
      "DR5M\n",
      "DR4M\n",
      "DR7M\n",
      "DR4F\n",
      "DR1M\n",
      "DR3F\n",
      "DR7M\n",
      "DR6F\n",
      "DR2M\n",
      "DR4M\n",
      "DR4M\n",
      "DR5F\n",
      "DR7M\n",
      "DR1F\n",
      "DR1F\n",
      "DR3M\n",
      "DR4F\n",
      "DR3F\n",
      "DR2M\n",
      "DR7M\n",
      "DR3M\n",
      "DR6M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]:   9%|▊         | 4/47 [00:06<01:14,  1.74s/it, loss=62.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR4M\n",
      "DR5F\n",
      "DR3M\n",
      "DR4M\n",
      "DR3F\n",
      "DR3M\n",
      "DR2M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m             loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 44\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     43\u001b[0m     loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mfccs, labels \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[1;32m     45\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     46\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(mfccs)\n",
      "File \u001b[0;32m~/miniconda3/envs/SP/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/SP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/SP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/SP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[12], line 70\u001b[0m, in \u001b[0;36mtrainset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mfcc_db, label_tensor\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     mel_spec \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwaveform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     mel_spec_db \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mpower_to_db(mel_spec, ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m     74\u001b[0m     max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m  \u001b[38;5;66;03m# 这个值可以根据数据集中最长的样本来设置\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SP/lib/python3.10/site-packages/librosa/feature/spectral.py:2143\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m S, n_fft \u001b[38;5;241m=\u001b[39m _spectrogram(\n\u001b[1;32m   2131\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   2132\u001b[0m     S\u001b[38;5;241m=\u001b[39mS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2139\u001b[0m     pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[1;32m   2140\u001b[0m )\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m-> 2143\u001b[0m mel_basis \u001b[38;5;241m=\u001b[39m \u001b[43mfilters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2145\u001b[0m melspec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...ft,mf->...mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, S, mel_basis, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "File \u001b[0;32m~/miniconda3/envs/SP/lib/python3.10/site-packages/librosa/filters.py:239\u001b[0m, in \u001b[0;36mmel\u001b[0;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[1;32m    236\u001b[0m     upper \u001b[38;5;241m=\u001b[39m ramps[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m fdiff[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# .. then intersect them with each other and zero\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     weights[i] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(norm, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslaney\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# Slaney-style mel is scaled to be approx constant energy per channel\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 在这部分，你可以选择不同的分类器和模型如GMM模型来进行实验\n",
    "class AudioLSTM(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(AudioLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=13, hidden_size=128, num_layers=2, batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(128, out_features=target)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(AudioCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
    "        output_size = 28800  # Adjusted calculation\n",
    "        self.fc1 = nn.Linear(output_size, 100)\n",
    "        self.fc2 = nn.Linear(100, target)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Adds a channel dimension\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = AudioCNN(target=target).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train_model(num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        for mfccs, labels in loop:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mfccs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "train_model(10)\n",
    "\n",
    "torch.save(model.state_dict(), \"model_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 评价指标(准确率Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请编写代码或使用库函数accuracy_score计算测试集上的准确率Accuracy\n",
    "\n",
    "model = AudioCNN(target=target)\n",
    "model.load_state_dict(torch.load(\"model_state_dict.pth\")).to(device)\n",
    "\n",
    "\n",
    "def test_model():\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mfccs, labels in test_loader:\n",
    "            outputs = model(mfccs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 计算正确的数量\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # 计算平均损失和准确度\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = total_correct / total_samples * 100\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  6. 分析和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请使用matplotlib等可视化库对你的实验结果进行可视化分析。\n",
    "## 包括但不限于准确率的对比、错误分类的分析、特征的影响等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 结果讨论\n",
    "讨论你的模型性能，尝试解释为什么某些模型比其他模型表现好，以及可能的改进方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 保存模型（可选）\n",
    "如果需要，可以在这里添加代码保存你的模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
